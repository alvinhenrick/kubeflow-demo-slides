<!doctype html>
<html>
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

    <title>Training and Serving Models on Kubernetes with Kubeflow</title>

    <link rel="stylesheet" href="css/reveal.css">
    <link rel="stylesheet" href="css/theme/league.css">

    <!-- Theme used for syntax highlighting of code -->
    <link rel="stylesheet" href="lib/css/zenburn.css">

    <!-- Printing and PDF exports -->
    <script>
        var link = document.createElement('link');
        link.rel = 'stylesheet';
        link.type = 'text/css';
        link.href = window.location.search.match(/print-pdf/gi) ? 'css/print/pdf.css' : 'css/print/paper.css';
        document.getElementsByTagName('head')[0].appendChild(link);
    </script>
    <style>
        .reveal .slides section .fragment.current-only {
            opacity: 1;
            visibility: visible;
            display: none;
        }

        .reveal .slides section .fragment.current-only.current-fragment {
            display: block;
        }

        /* Solarized Light theme */
        .line {
            display: block;
        }

        .line.focus {
            background: #fdf6e3;
            color: #657b83;
            width: max-content;
        }

        .line.focus .hljs-comment, .line.focus .hljs-quote {
            color: #93a1a1;
        }

        .line.focus .hljs-keyword, .line.focus .hljs-selector-tag, .line.focus .hljs-addition {
            color: #859900;
        }

        .line.focus .hljs-number, .line.focus .hljs-string, .line.focus .hljs-meta .hljs-meta-string, .line.focus .hljs-literal, .line.focus .hljs-doctag, .line.focus .hljs-regexp {
            color: #2aa198;
        }

        .line.focus .hljs-title, .line.focus .hljs-section, .line.focus .hljs-name, .line.focus .hljs-selector-id, .line.focus .hljs-selector-class {
            color: #268bd2;
        }

        .line.focus .hljs-attribute, .line.focus .hljs-attr, .line.focus .hljs-variable, .line.focus .hljs-template-variable, .line.focus .hljs-class .hljs-title, .line.focus .hljs-type {
            color: #b58900;
        }

        .line.focus .hljs-symbol, .line.focus .hljs-bullet, .line.focus .hljs-subst, .line.focus .hljs-meta, .line.focus .hljs-meta .hljs-keyword, .line.focus .hljs-selector-attr, .line.focus .hljs-selector-pseudo, .line.focus .hljs-link {
            color: #cb4b16;
        }

        .line.focus .hljs-built_in, .line.focus .hljs-deletion {
            color: #dc322f;
        }

        .line.focus .hljs-formula {
            background: #eee8d5;
        }

        .line.focus .hljs-emphasis {
            font-style: italic;
        }

        .line.focus .hljs-strong {
            font-weight: bold;
        }

        .yellow-slide .line.focus:nth-child(2) {
            background: yellow;
        }
    </style>
</head>
<body>
<div class="reveal">
    <div class="slides">
        <section>
            <h1><img src="images/Kubeflow_Logo.png" width="200" height="202"></h1>
            The Kubeflow project is dedicated to making deployments of machine learning (ML) workflows on Kubernetes
            simple, portable and scalable.
            Anywhere you are running Kubernetes, you should be able to run Kubeflow.
        </section>
        <section>
            <h1><img src="images/Ambassador_Logo.png" width="321" height="80"></h1>
            Ambassador is an open source, Kubernetes-native microservices API gateway built on the Envoy Proxy.
            Ambassador is built from the ground up to support multiple, independent teams that need to rapidly publish,
            monitor, and update services for end users.
            Ambassador can also be used to handle the functions of a Kubernetes ingress controller and load balancer.
        </section>
        <section>
            <h1><img src="images/Seldon_Logo.jpg" width="400" height="100"></h1>
            Seldon a serving container to export trained models to Kubernetes.
            Kubeflow integrates with Seldon Core, the open source platform for deploying machine learning models on
            Kubernetes.
        </section>
        <section>
            <h1><img src="images/Ksonnet_Logo.png" width="200" height="202"></h1>
            Packaging framework for extensible Kubernetes configurations.
            Built on the JSON templating language Jsonnet, Ksonnet provides an organizational structure and specialized
            features for managing configurations across different clusters and environments.
        </section>
        <section>
            <section>
                <h1>DEMO 1</h1>
                <p>Simple Iris Classification</p>
                <a href="#" class="navigate-down">Discuss Makefile</a>
            </section>
            <section>
                <h3>Makefile</h3>
                <pre><code data-trim>
                    VERSION=1.1
                    TRAIN_IMAGE_BASE=alvinhenrick/kube-demo-simple
                    SERVE_IMAGE_BASE=alvinhenrick/iris-classification

                    build:
                        docker build -t ${TRAIN_IMAGE_BASE}:${VERSION} .

                    login:
                        docker login

                    push:
                        docker push ${TRAIN_IMAGE_BASE}:${VERSION}

                    createpvc:
                        kubectl apply -f mystorage.yaml

                    deletepvc:
                        kubectl delete -f mystorage.yaml

                    copydata:
                        kubectl cp ./iris dataaccess:/data/

                    train:
                        kubectl apply -f tfjobsimple.yaml

                    download:
                        kubectl cp dataaccess:/model/iris_model ./iris_model

                    s2i:
                        s2i build . seldonio/seldon-core-s2i-python3:0.1 ${SERVE_IMAGE_BASE}:${VERSION} --copy ./iris_model --env MODEL_NAME=IrisClassifier --env API_TYPE=REST --env SERVICE_TYPE=MODEL --env PERSISTENCE=0

                    s2ipush:
                        docker push ${SERVE_IMAGE_BASE}:${VERSION}

                    serve:
                        cd simple_demo_ks ; ks generate seldon-serve-simple iris-classification --image=${SERVE_IMAGE_BASE}:${VERSION}
                        cd simple_demo_ks ; ks apply default -c iris-classification

                    portforward:
                        kubectl port-forward `kubectl get pods -n default -l service=ambassador -o jsonpath='{.items[0].metadata.name}'` -n default 8080:80

                    predict:
                        curl -X POST -H 'Content-Type: application/json' -d '{"data":{"ndarray":[[5.9, 3.0, 4.2, 1.5],[6.9, 3.1, 5.4, 2.1],[5.1, 3.3, 1.7, 0.5]]}}' http://localhost:8080/seldon/iris-classification/api/v0.1/predictions

                    tail:
                        kubectl logs -f kube-demo-simple-master-0

                    tailseldon:
                        kubectl logs -f `kubectl get pods -l seldon-app=iris-classification -o=jsonpath='{.items[0].metadata.name}'` iris-classification

                    stop:
                        kubectl delete -f tfjobsimple.yaml

                    clean:
                        cd simple_demo_ks ; ks delete default -c iris-classification
                        cd simple_demo_ks ; ks component rm iris-classification
                        # ksonnet delete and remove component
                    </code></pre>
                <p class="fragment current-only" data-code-focus="1-3">Declare the variable,tag and version for
                    training and serving docker image.</p>
                <p class="fragment current-only" data-code-focus="5-6">Docker build training image.</p>
                <p class="fragment current-only" data-code-focus="8-9">Login to your docker hub account.</p>
                <p class="fragment current-only" data-code-focus="11-12">Push the training docker image to docker
                    hub.</p>
                <p class="fragment current-only" data-code-focus="14-18">Create/Delete Persistence volume container.</p>
                <p class="fragment current-only" data-code-focus="20-21">Copy training data into Persistence volume
                    container.</p>
                <p class="fragment current-only" data-code-focus="23-24">Run the training job with Kubeflow.</p>
                <p class="fragment current-only" data-code-focus="26-27">Download the trained model.</p>
                <p class="fragment current-only" data-code-focus="29-30">Build model serving docker image with S2i.</p>
                <p class="fragment current-only" data-code-focus="32-33">Push the serving docker image to docker
                    hub.</p>
                <p class="fragment current-only" data-code-focus="35-37">Serve the model with Kubeflow and Seldon.</p>
                <p class="fragment current-only" data-code-focus="39-40">Forward the port from the Ambassador container
                    to localhost.</p>
                <p class="fragment current-only" data-code-focus="42-43">Make predictions via REST API and Seldon
                    through the Ambassador proxy setup by Kubeflow.</p>
                <p class="fragment current-only" data-code-focus="45-46">Tail the training container log for
                    debugging.</p>
                <p class="fragment current-only" data-code-focus="48-49">Tail the seldon serving container log for
                    debugging.</p>
                <p class="fragment current-only" data-code-focus="51-52">Clean up training job.</p>
                <p class="fragment current-only" data-code-focus="54-56">Clean up seldon serving job.</p>
            </section>
        </section>
        <section>
            <h3>TFJob</h3>
            <pre><code data-trim>
                ---
                apiVersion: "kubeflow.org/v1alpha2"
                kind: TFJob
                metadata:
                  name: kube-demo-dist
                spec:
                  tfReplicaSpecs:
                    Master:
                      replicas: 1
                      template:
                        spec:
                          containers:
                          - name: tensorflow
                            image: alvinhenrick/kube-demo-dist:1.1
                            command: ["python", "/code/train_and_eval.py","--output_path=/model/imdb_model"]
                            volumeMounts:
                            - name: data
                              mountPath: "/data"
                            - name: models
                              mountPath: "/model"
                          volumes:
                          - name: data
                            persistentVolumeClaim:
                              claimName: mydata
                          - name: models
                            persistentVolumeClaim:
                              claimName: mymodels
                    Worker:
                      replicas: 3
                      template:
                        spec:
                          containers:
                          - name: tensorflow
                            image: alvinhenrick/kube-demo-dist:1.1
                            command: ["python", "/code/train_and_eval.py","--output_path=/model/imdb_model"]
                            volumeMounts:
                            - name: data
                              mountPath: "/data"
                            - name: models
                              mountPath: "/model"
                          volumes:
                          - name: data
                            persistentVolumeClaim:
                              claimName: mydata
                          - name: models
                            persistentVolumeClaim:
                              claimName: mymodels
                    PS:
                      replicas: 2
                      template:
                        spec:
                          containers:
                          - name: tensorflow
                            image: alvinhenrick/kube-demo-dist:1.1
                            command: ["python", "/code/train_and_eval.py","--output_path=/model/imdb_model"]
                            volumeMounts:
                            - name: data
                              mountPath: "/data"
                            - name: models
                              mountPath: "/model"
                            ports:
                            - containerPort: 6006
                          volumes:
                          - name: data
                            persistentVolumeClaim:
                              claimName: mydata
                          - name: models
                            persistentVolumeClaim:
                              claimName: mymodels
                </code></pre>
            <p class="fragment current-only" data-code-focus="3">TFJob is a Kubernetes custom resource
                definition that makes it easy to run TensorFlow training jobs.</p>
            <p class="fragment current-only" data-code-focus="8-9">The Master is responsible for orchestrating
                training and performing tasks like checkpointing the model.</p>
            <p class="fragment current-only" data-code-focus="13-15">Kubernetes training container
                specification</p>
            <p class="fragment current-only" data-code-focus="21-27">Kubernetes Persistent volume mounts</p>
            <p class="fragment current-only" data-code-focus="28-29">The Worker do the actual work of training
                the model. In some cases, worker 0 might also act as the Master.</p>
            <p class="fragment current-only" data-code-focus="48-49">The PS are parameter servers; these servers
                provide a distributed data store for the model parameters.</p>
        </section>
        <section>
            <section data-markdown>
                <script type="text/template">
                    ### Seldon Core
                    Instead of just serving up single models behind an API endpoint, Seldon Core allows complex runtime inference graphs to be deployed in containers as microservices.
                </script>
            </section>

            <section data-markdown>
                <script type="text/template">
                    ### These graphs can be composed of:
                    1. **Models** — runtime inference executable for one or more machine learning models.
                    2. **Routers** — route API requests to sub-graphs. E.g. to serve experiments such as A/B Tests or more dynamic Multi-Armed Bandits (MAB).
                    3. **Combiners** — combine the responses from sub-graphs. E.g. ensembles of models.
                    4. **Transformers** — transform request or responses. E.g. transform feature requests.
                </script>
            </section>
            <section>
                <h3>The example graphs</h3>
                <img src="images/SeldonGraphs.png">
                </br>
                <a href="https://github.com/cliveseldon/seldon-core/blob/master/notebooks/advanced_graphs.ipynb"
                   target="_b">Advance Graphs</a>
            </section>
            <section>
                <h3>Seldon Deployment</h3>
                <pre><code data-trim>
                    {
                      "apiVersion": "machinelearning.seldon.io/v1alpha2",
                      "kind": "SeldonDeployment",
                      "metadata": {
                        "labels": {
                          "app": "seldon"
                        },
                        "name": "your-deployment-name"
                      },
                      "spec": {
                        "annotations": {
                          "project_name": "your project name",
                          "deployment_version": "your-deployment-version"
                        },
                        "name": "your-deployment-name",
                        "oauth_key": "oauth-key",
                        "oauth_secret": "oauth-secret",
                        "predictors": [
                          {
                            "componentSpecs": [
                              {
                                "spec": {
                                  "containers": [
                                    {
                                      "image": "your-docker-image",
                                      "imagePullPolicy": "IfNotPresent or Always etc",
                                      "name": "your-model-name",
                                      "resources": {
                                        "requests": {
                                          "memory": ""
                                        }
                                      }
                                    }
                                  ],
                                  "terminationGracePeriodSeconds": ""
                                }
                              }
                            ],
                            "graph": {
                              "children": [],
                              "name": "your-model-name",
                              "endpoint": {
                                "type": "your-endpoint-type #REST or #GRPC"
                              },
                              "type": "MODEL"
                            },
                            "name": "your-model-name",
                            "replicas": "# Number of replica",
                            "annotations": {
                              "predictor_version": "your-model-version"
                            }
                          }
                        ]
                      }
                    }
                </code></pre>
                <p class="fragment current-only" data-code-focus="3">
                    SeldonDeployment is a Kubernetes custom resource definition that makes it easy to server models on
                    Kubernetes.
                </p>
                <p class="fragment current-only" data-code-focus="23-33">Seldon serving container specification</p>
                <p class="fragment current-only" data-code-focus="39-52">The deployment graph definition</p>
            </section>
        </section>
        <section>
            <h1>DEMO 2</h1>
            <p>Simple IMDB Document Classification</p>
        </section>
        <section>
            <p>Thank you!!!!</p>
        </section>
    </div>
</div>

<script src="lib/js/head.min.js"></script>
<script src="js/reveal.js"></script>

<script>
    // More info about config & dependencies:
    // - https://github.com/hakimel/reveal.js#configuration
    // - https://github.com/hakimel/reveal.js#dependencies
    Reveal.initialize({
        dependencies: [
            {src: 'plugin/markdown/marked.js'},
            {src: 'plugin/markdown/markdown.js'},
            {src: 'plugin/notes/notes.js', async: true},
            {src: 'plugin/highlight/highlight.js'},
            {
                src: 'plugin/reveal-code-focus/reveal-code-focus.js',
                async: true,
                callback: function () {
                    RevealCodeFocus();
                }
            }
            // {
            //     src: 'plugin/highlight/highlight.js', async: true, callback: function () {
            //         hljs.initHighlightingOnLoad();
            //     }
            // }
        ]
    });
</script>
</body>
</html>
